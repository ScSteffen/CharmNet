import pyapprox.multifidelity.etc as etc
from pyapprox.variables.joint import IndependentMarginalsVariable
import numpy as np
from scipy import stats
import time
import pickle

from src.models.hohlraum import get_qois_col_names, model
from src.general_utils import parse_args
from src.general_utils import (
    create_hohlraum_samples_from_param_range,
    load_hohlraum_samples_from_npz,
    delete_slurm_scripts,
)
from src.simulation_utils import execute_slurm_scripts, wait_for_slurm_jobs
from src.config_utils import read_username_from_config


np.random.seed(1)
# import model from client_hohlraum


def generate_model(cell_length, nquad, hpc_operation, singularity_hpc, qoi_idx):
    """
    Return a function that can be passed to the AETC algorithm
    cell_length (float): the model hyperparameter
    nquad (int): the model hyperparameter
    hpc_operation_count (int): parameter to indicate how the model is run
    singularity_hpc (bool): parameter to indicate how the model is run
    qoi_idx (int): Index of the qoi whose mean we want to estimate
    """

    # np.ndarray (nvars, nsamples) -> np.ndarary (nsamples, nqoi)
    def eval_model(samples):
        size = samples.shape
        extras = np.zeros((4, size[1]))
        extras[2, :] = cell_length
        extras[3, :] = nquad
        design_params = np.concatenate((samples, extras), axis=0)

        if hpc_operation:
            print("==== Execute HPC version ====")
            directory = "./benchmarks/hohlraum/slurm_scripts/"
            user = read_username_from_config("./slurm_config.txt")

            delete_slurm_scripts(directory)  # delete existing slurm files for hohlraum
            call_models(
                design_params, hpc_operation_count=1, singularity_hpc=singularity_hpc
            )
            wait_for_slurm_jobs(user=user, sleep_interval=10)
            if user:
                print("Executing slurm scripts with user " + user)
                execute_slurm_scripts(directory, user)
                wait_for_slurm_jobs(user=user, sleep_interval=10)
            else:
                print("Username could not be read from slurm config file.")
            qois = call_models(design_params, hpc_operation_count=2)
        else:
            qois = call_models(design_params, hpc_operation_count=0)

        qois = np.array(qois)
        # wall_times = qois[0]
        qoi_result = qois[:, qoi_idx].reshape(-1, 1)
        return qoi_result

    def call_models(design_params, hpc_operation_count, singularity_hpc=True):
        qois = []
        for column in design_params.T:
            input = column.tolist()
            input.append(hpc_operation_count)
            input.append(singularity_hpc)
            res = model([input])
            qois.append(res[0])

        return np.array(qois)

    return eval_model


def main():

    args = parse_args()
    print(f"HPC mode = { not args.no_hpc}")
    print(f"Load from npz = {args.load_from_npz}")
    print(f"HPC with singularity = { not args.no_singularity_hpc}")

    hpc_operation = not args.no_hpc  # Flag when using HPC cluster
    singularity_hpc = not args.no_singularity_hpc

    # Define the model parameters that declare the fidelity
    #   Each element is one fidelity
    #   Highest fidelity comes first
    cell_lengths = [5e-3, 7.5e-3, 1e-2]
    nquads = [8, 8, 8]

    # Generate the models into an array
    #   Include the correct HPC parameters
    models = np.array(
        [
            generate_model(
                cell_length=cl,
                nquad=nq,
                hpc_operation=hpc_operation,
                singularity_hpc=singularity_hpc,
                qoi_idx=1,
            )
            for (cl, nq) in zip(cell_lengths, nquads)
        ]
    )

    # Update the ranges of the variables to match what CharmKiT needs
    # marginals = [stats.uniform(0.1, 0.2)]*4 + [stats.uniform(0.025, 0.05)]*2
    marginals = [
        stats.uniform(
            0.3, 0.2
        ),  # first entry: lower bound, second entry: length of intervall
        stats.uniform(-0.5, 0.2),
        stats.uniform(0.3, 0.2),
        stats.uniform(-0.5, 0.2),
        stats.uniform(-0.625, 0.5),
        stats.uniform(0.575, 0.5),
    ]
    variable = IndependentMarginalsVariable(marginals)
    sample_variable = variable.rvs

    # Run each model 1 time to estimate the model cost in seconds
    #   In the future, this will be done inside of the AETC algorithm to progressively get better estimates
    n_time_samples = 1
    costs = []
    for model in models:
        s = time.time()
        model(sample_variable(n_time_samples))
        e = time.time()
        costs.append((e - s) / n_time_samples)

    print("Costs: ", [f"{costs[i]:.2E}" for i, _ in enumerate(models)])

    # This is the total budget in seconds that the total model run time will not exceed
    #   Note that since the model costs are estimates, the algorithm may take longer than the given budget
    #   This budget does not include the overhead that the AETC takes to run
    budget = 120

    # Construct the estimator
    estimator = etc.AETCBLUE(models, sample_variable, costs=costs)

    # Explore phase
    samples, values, result = estimator.explore(budget, None)

    # Exploit phase
    samples_per_model, best_subset = estimator.get_exploit_samples(result)

    # Run the `best_subset` models here using the input samples: `samples_per_model`
    values_per_model = [
        models[s](samples) for s, samples in zip(best_subset, samples_per_model)
    ]

    # Run the estimator
    mean = estimator.find_exploit_mean(values_per_model, result)

    # Print or save the results
    print("AETC Algorithm ran successfully")
    print("Mean of qoi:", mean)
    print("Result Dictionary:", result)


if __name__ == "__main__":
    main()
